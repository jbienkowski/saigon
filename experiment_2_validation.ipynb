{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c91ac9ee",
   "metadata": {},
   "source": [
    "Notes:\n",
    "```\n",
    "tf.keras.utils.plot_model(gan_model, to_file='msc-experiment1-ganmodel.png', show_shapes=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a81b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from scipy.signal import spectrogram, stft, istft\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4742cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the constants\n",
    "FS = 66\n",
    "NPERSEG = 127\n",
    "SAMPLES = 4000\n",
    "STFT_SIZE = 64\n",
    "N_SAMPLES = 10000\n",
    "KEYS_VALID = None\n",
    "Y_VALID = None\n",
    "X_VALID = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seismograms(do, label, file_path=None):\n",
    "    do = istft(do.transpose(2, 0, 1), fs=FS, nperseg=NPERSEG)[1]\n",
    "    d0 = pd.DataFrame(data=do[0][:SAMPLES])\n",
    "    d1 = pd.DataFrame(data=do[1][:SAMPLES])\n",
    "    d2 = pd.DataFrame(data=do[2][:SAMPLES])\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 5), dpi=80)\n",
    "    ax1 = plt.subplot2grid((3, 1), (0, 0), colspan=1)\n",
    "    ax2 = plt.subplot2grid((3, 1), (1, 0), colspan=1)\n",
    "    ax3 = plt.subplot2grid((3, 1), (2, 0), colspan=1)\n",
    "\n",
    "    plt.subplots_adjust(hspace=1, wspace=1)\n",
    "\n",
    "    sns.lineplot(data=d0, ax=ax1, linewidth=1, legend=None)\n",
    "    sns.lineplot(data=d1, ax=ax2, linewidth=1, legend=None)\n",
    "    sns.lineplot(data=d2, ax=ax3, linewidth=1, legend=None)\n",
    "\n",
    "    ax1.set_title(\"Vertical component waveform\")\n",
    "    ax1.set(xlabel=\"Samples\", ylabel=\"Amplitude counts\")\n",
    "    ax1.locator_params(nbins=6, axis=\"y\")\n",
    "\n",
    "    ax2.set_title(\"North component waveform\")\n",
    "    ax2.set(xlabel=\"Samples\", ylabel=\"Amplitude counts\")\n",
    "    ax2.locator_params(nbins=6, axis=\"y\")\n",
    "\n",
    "    ax3.set_title(\"East component waveform\")\n",
    "    ax3.set(xlabel=\"Samples\", ylabel=\"Amplitude counts\")\n",
    "    ax3.locator_params(nbins=6, axis=\"y\")\n",
    "\n",
    "    plt.suptitle(label, fontsize=14)\n",
    "\n",
    "    if file_path != None:\n",
    "        plt.savefig(file_path)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da58e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(do, label, file_path=None):\n",
    "    do = istft(do.transpose(2, 0, 1), fs=FS, nperseg=NPERSEG)[1]\n",
    "    d0 = pd.DataFrame(data=do[0][:SAMPLES])\n",
    "    d1 = pd.DataFrame(data=do[1][:SAMPLES])\n",
    "    d2 = pd.DataFrame(data=do[2][:SAMPLES])\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 10), dpi=80)\n",
    "    ax1 = plt.subplot2grid((5, 6), (0, 0), colspan=3)\n",
    "    ax2 = plt.subplot2grid((5, 6), (1, 0), colspan=3)\n",
    "    ax3 = plt.subplot2grid((5, 6), (2, 0), colspan=3)\n",
    "    ax4 = plt.subplot2grid((5, 6), (0, 3), colspan=3)\n",
    "    ax5 = plt.subplot2grid((5, 6), (1, 3), colspan=3)\n",
    "    ax6 = plt.subplot2grid((5, 6), (2, 3), colspan=3)\n",
    "    ax7 = plt.subplot2grid((5, 6), (3, 0), colspan=2, rowspan=2)\n",
    "    ax8 = plt.subplot2grid((5, 6), (3, 2), colspan=2, rowspan=2)\n",
    "    ax9 = plt.subplot2grid((5, 6), (3, 4), colspan=2, rowspan=2)\n",
    "\n",
    "    plt.subplots_adjust(hspace=1, wspace=1)\n",
    "\n",
    "    sns.lineplot(data=d0, ax=ax1, linewidth=1, legend=None)\n",
    "    sns.lineplot(data=d1, ax=ax2, linewidth=1, legend=None)\n",
    "    sns.lineplot(data=d2, ax=ax3, linewidth=1, legend=None)\n",
    "\n",
    "    ax1.set_title(\"Vertical component waveform\")\n",
    "    ax1.set(xlabel=\"Samples\", ylabel=\"Amplitude counts\")\n",
    "    ax1.locator_params(nbins=6, axis=\"y\")\n",
    "\n",
    "    ax2.set_title(\"North component waveform\")\n",
    "    ax2.set(xlabel=\"Samples\", ylabel=\"Amplitude counts\")\n",
    "    ax2.locator_params(nbins=6, axis=\"y\")\n",
    "\n",
    "    ax3.set_title(\"East component waveform\")\n",
    "    ax3.set(xlabel=\"Samples\", ylabel=\"Amplitude counts\")\n",
    "    ax3.locator_params(nbins=6, axis=\"y\")\n",
    "\n",
    "    f_0, t_0, Sxx_0 = spectrogram(x=do[0], fs=FS)\n",
    "    f_1, t_1, Sxx_1 = spectrogram(x=do[1], fs=FS)\n",
    "    f_2, t_2, Sxx_2 = spectrogram(x=do[2], fs=FS)\n",
    "\n",
    "    ax4.clear()\n",
    "    ax4.set_title(\"Vertical component spectrogram\")\n",
    "    _ax4 = ax4.pcolormesh(t_0, f_0, Sxx_0, shading=\"gouraud\")\n",
    "    ax4.set(xlabel=\"Time [sec]\", ylabel=\"Frequency [Hz]\")\n",
    "    fig.colorbar(_ax4, ax=ax4)\n",
    "\n",
    "    ax5.clear()\n",
    "    ax5.set_title(\"North component spectrogram\")\n",
    "    _ax5 = ax5.pcolormesh(t_1, f_1, Sxx_1, shading=\"gouraud\")\n",
    "    ax5.set(xlabel=\"Time [sec]\", ylabel=\"Frequency [Hz]\")\n",
    "    fig.colorbar(_ax5, ax=ax5)\n",
    "\n",
    "    ax6.clear()\n",
    "    ax6.set_title(\"East component spectrogram\")\n",
    "    _ax6 = ax6.pcolormesh(t_2, f_2, Sxx_2, shading=\"gouraud\")\n",
    "    ax6.set(xlabel=\"Time [sec]\", ylabel=\"Frequency [Hz]\")\n",
    "    fig.colorbar(_ax6, ax=ax6)\n",
    "\n",
    "    f_sftt_0, t_sftt_0, Zxx_0 = stft(do[0], window=\"hanning\", fs=FS, nperseg=NPERSEG)\n",
    "    f_sftt_1, t_sftt_1, Zxx_1 = stft(do[1], window=\"hanning\", fs=FS, nperseg=NPERSEG)\n",
    "    f_sftt_2, t_sftt_2, Zxx_2 = stft(do[2], window=\"hanning\", fs=FS, nperseg=NPERSEG)\n",
    "\n",
    "    ticks = np.arange(STFT_SIZE)\n",
    "\n",
    "    ax7.clear()\n",
    "    ax7.set_title(\"Vertical component STFT\")\n",
    "    _ax7 = ax7.pcolormesh(ticks, ticks, np.abs(Zxx_0), shading=\"auto\")\n",
    "    fig.colorbar(_ax7, ax=ax7)\n",
    "\n",
    "    ax8.clear()\n",
    "    ax8.set_title(\"North component STFT\")\n",
    "    _ax8 = ax8.pcolormesh(ticks, ticks, np.abs(Zxx_1), shading=\"auto\")\n",
    "    fig.colorbar(_ax8, ax=ax8)\n",
    "\n",
    "    ax9.clear()\n",
    "    ax9.set_title(\"East component STFT\")\n",
    "    _ax9 = ax9.pcolormesh(ticks, ticks, np.abs(Zxx_2), shading=\"auto\")\n",
    "    fig.colorbar(_ax9, ax=ax9)\n",
    "\n",
    "    plt.suptitle(label, fontsize=14)\n",
    "\n",
    "    if file_path != None:\n",
    "        plt.savefig(file_path)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a817f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"data/stead_test_stft_64.hdf5\", \"r\") as f:\n",
    "    KEYS_VALID = f[\"keys\"][:N_SAMPLES]\n",
    "    Y_VALID = f[\"labels\"][:N_SAMPLES]\n",
    "    X_VALID = f[\"data\"][:N_SAMPLES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a941d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = tf.keras.models.load_model(\"out2/desc-10\")\n",
    "pred = disc.predict(X_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79954f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true=Y_VALID, y_pred=np.round(abs(pred)))\n",
    "nr_rows = conf_matrix.shape[0]\n",
    "nr_cols = conf_matrix.shape[1]\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(conf_matrix, cmap=plt.cm.Blues)\n",
    "\n",
    "# plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.ylabel('Actual labels', fontsize=12)\n",
    "plt.xlabel('Predicted labels', fontsize=12)\n",
    "\n",
    "tick_marks = np.arange(2)\n",
    "plt.yticks(tick_marks, [\"AN\", \"EQ\"])\n",
    "plt.xticks(tick_marks, [\"AN\", \"EQ\"])\n",
    "\n",
    "for i, j in itertools.product(range(nr_rows), range(nr_cols)):\n",
    "    plt.text(j, i, conf_matrix[i, j], horizontalalignment='center',\n",
    "    color='white' if conf_matrix[i, j] > conf_matrix.max()/2 else 'black')\n",
    "\n",
    "plt.savefig(\"msc-experiment2-confmatrix.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef950685",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12, 6])\n",
    "\n",
    "plt.xlim([0, 50])\n",
    "plt.ylim([0, 100])\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "# plt.title('Discriminator accuracy', fontsize=17)\n",
    "plt.xlabel('Epochs', fontsize=24)\n",
    "plt.ylabel('Accuracy', fontsize=24)\n",
    "\n",
    "# 2) X Axis Data: create a list from 0 to n + 1\n",
    "iteration_list = [x for x in range(51) if x%2==0]\n",
    "vals = [0, 62.8, 78.8, 85.1, 84.9, 86.2, 86.3, 85.5, 79.2, 79.7, 77.4, 76.7, 72.8, 73.6, 69.7, 68.6, 69.7, 70.9, 68.4, 66.8, 67.7, 65.3, 65.6, 63.9, 63.7, 69.6]\n",
    "\n",
    "# Plotting low learning rate\n",
    "plt.plot(iteration_list, np.array(vals), color='steelblue', linewidth=2)\n",
    "plt.scatter(iteration_list, np.array(vals), color=\"steelblue\", s=100)\n",
    "\n",
    "# # Plotting mid learning rate\n",
    "# plt.plot(iteration_list, g(mid_values), color='steelblue', linewidth=5)\n",
    "# plt.scatter(iteration_list, g(mid_values), color=\"steelblue\", s=80)\n",
    "\n",
    "# # Plotting high learning rate\n",
    "# plt.plot(iteration_list, g(high_values), color='hotpink', linewidth=5)\n",
    "# plt.scatter(iteration_list, g(high_values), color=\"hotpink\", s=80)\n",
    "\n",
    "# # Plotting insane learning rate\n",
    "# plt.plot(iteration_list, g(insane_values), color='red', linewidth=5)\n",
    "# plt.scatter(iteration_list, g(insane_values), color=\"red\", s=80)\n",
    "plt.grid()\n",
    "plt.savefig(\"msc-experiment2-disc-accuracy.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f203e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(200,300):\n",
    "    print(idx)\n",
    "    print(f\"Label: {KEYS_VALID[idx]}\")\n",
    "    print(f\"Predicted accuracy: {pred[idx]}\")\n",
    "    print(f\"Real class: {Y_VALID[idx]}\")\n",
    "    print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141de16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 500\n",
    "print(f\"Label: {KEYS_VALID[idx]}\")\n",
    "# print(f\"Predicted accuracy: {pred[idx]}\")\n",
    "print(f\"Real class: {Y_VALID[idx]}\")\n",
    "plot_all(X_VALID[idx], KEYS_VALID[idx].decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253ec519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(2 * 2 * 256, use_bias=False, input_shape=(latent_dim,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((2, 2, 256)))\n",
    "\n",
    "    model.add(\n",
    "        layers.Conv2DTranspose(\n",
    "            32, (20, 20), strides=(2, 2), padding=\"same\", use_bias=False\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.1))\n",
    "\n",
    "    model.add(\n",
    "        layers.Conv2DTranspose(\n",
    "            32, (4, 4), strides=(2, 2), padding=\"same\", use_bias=False\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.1))\n",
    "\n",
    "    model.add(\n",
    "        layers.Conv2DTranspose(\n",
    "            32, (4, 4), strides=(2, 2), padding=\"same\", use_bias=False\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.1))\n",
    "\n",
    "    model.add(\n",
    "        layers.Conv2DTranspose(\n",
    "            32, (4, 4), strides=(2, 2), padding=\"same\", use_bias=False\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.1))\n",
    "\n",
    "    model.add(\n",
    "        layers.Conv2DTranspose(\n",
    "            32, (4, 4), strides=(2, 2), padding=\"same\", use_bias=False\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.1))\n",
    "\n",
    "    model.add(\n",
    "        layers.Conv2DTranspose(\n",
    "            3,\n",
    "            (3, 3),\n",
    "            padding=\"same\",\n",
    "            use_bias=False,\n",
    "            activation=\"linear\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefdb520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (1, 1), padding=\"same\", input_shape=[STFT_SIZE, STFT_SIZE, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (4, 4), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (4, 4), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (4, 4), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (4, 4), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (4, 4), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    opt = Adam(learning_rate=0.0001, beta_1=0.5)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d9a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model = make_generator_model(100)\n",
    "g_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c9e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = make_discriminator_model()\n",
    "d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2cc6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
