{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from time import strftime\n",
    "from scipy.signal import spectrogram, stft, istft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f937960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"GanPlayground\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(do, label):\n",
    "    d0 = pd.DataFrame(data=do[0])\n",
    "    d1 = pd.DataFrame(data=do[1])\n",
    "    d2 = pd.DataFrame(data=do[2])\n",
    "\n",
    "    _, axes = plt.subplots(3, 2, figsize=(14, 6))\n",
    "    plt.subplots_adjust(hspace=0.80)\n",
    "\n",
    "    sns.lineplot(data=d0, ax=axes[0, 0], linewidth=1, legend=None)\n",
    "    sns.lineplot(data=d1, ax=axes[1, 0], linewidth=1, legend=None)\n",
    "    sns.lineplot(data=d2, ax=axes[2, 0], linewidth=1, legend=None)\n",
    "\n",
    "    axes[0, 0].set_title(\"Vertical (Z) component\")\n",
    "    axes[0, 0].set(xlabel=\"Samples\", ylabel=\"Amplitude counts\")\n",
    "    axes[0, 0].locator_params(nbins=6, axis=\"y\")\n",
    "\n",
    "    axes[1, 0].set_title(\"Horizontal (N) component\")\n",
    "    axes[1, 0].set(xlabel=\"Samples\", ylabel=\"Amplitude counts\")\n",
    "    axes[1, 0].locator_params(nbins=6, axis=\"y\")\n",
    "\n",
    "    axes[2, 0].set_title(\"Horizontal (E) component\")\n",
    "    axes[2, 0].set(xlabel=\"Samples\", ylabel=\"Amplitude counts\")\n",
    "    axes[2, 0].locator_params(nbins=6, axis=\"y\")\n",
    "    \n",
    "    f_0, t_0, Sxx_0 = spectrogram(x=do[0], fs=100)\n",
    "    f_1, t_1, Sxx_1 = spectrogram(x=do[1], fs=100)\n",
    "    f_2, t_2, Sxx_2 = spectrogram(x=do[2], fs=100)\n",
    "\n",
    "    axes[0, 1].clear()\n",
    "    axes[0, 1].set_title(\"Vertical (Z) component\")\n",
    "    axes[0, 1].pcolormesh(t_0, f_0, Sxx_0, shading=\"gouraud\")\n",
    "    axes[0, 1].set(xlabel=\"Time [sec]\", ylabel=\"Frequency [Hz]\")\n",
    "\n",
    "    axes[1, 1].clear()\n",
    "    axes[1, 1].set_title(\"Horizontal (N) component\")\n",
    "    axes[1, 1].pcolormesh(t_1, f_1, Sxx_1, shading=\"gouraud\")\n",
    "    axes[1, 1].set(xlabel=\"Time [sec]\", ylabel=\"Frequency [Hz]\")\n",
    "\n",
    "    axes[2, 1].clear()\n",
    "    axes[2, 1].set_title(\"Horizontal (E) component\")\n",
    "    axes[2, 1].pcolormesh(t_2, f_2, Sxx_2, shading=\"gouraud\")\n",
    "    axes[2, 1].set(xlabel=\"Time [sec]\", ylabel=\"Frequency [Hz]\")\n",
    "\n",
    "    plt.subplots_adjust(top=0.88)\n",
    "\n",
    "    title = \"Earthquake\" if label == 1 else \"Noise\"\n",
    "    plt.suptitle(title, fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3cb57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_path, idx_start, idx_end, idx_slice):\n",
    "    x_train = None\n",
    "    y_train = None\n",
    "    x_test = None\n",
    "    y_test = None\n",
    "    with h5py.File(file_path, \"r\") as f:\n",
    "        x_train = f[\"data\"][idx_start:idx_slice]\n",
    "        y_train = f[\"labels\"][idx_start:idx_slice]\n",
    "        x_test = f[\"data\"][idx_slice:idx_end]\n",
    "        y_test = f[\"labels\"][idx_slice:idx_end]\n",
    "        return (x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97daaf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stfts(x, y):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for idx, triplet in enumerate(x):\n",
    "        for stream in triplet:\n",
    "            _, _, zxx = stft(stream, window='hanning', nperseg=155)\n",
    "            x_train.append(np.abs(zxx))\n",
    "            y_train.append(y[idx])\n",
    "\n",
    "    return (x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f59a544",
   "metadata": {},
   "source": [
    "# Read processed data\n",
    "\n",
    "`x_?` is a dataset of streams:\n",
    "\n",
    "`x_?[0][0]` -> Z component\n",
    "\n",
    "`x_?[0][1]` -> N component\n",
    "\n",
    "`x_?[0][2]` -> E component\n",
    "\n",
    "`y_?` is a dataset of labels corresponding to streams. `1` means earthquake, `0` means noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee766d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_1, y_1, x_2, y_2) = get_data(\"../data/STEAD-processed.hdf5\", 10000, 20000, 18000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafbc17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(x_1[10], y_1[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c16cf",
   "metadata": {},
   "source": [
    "# Convert streams to STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STFT of the stream and then reverse STFT back into original stream\n",
    "# f, t, Zxx = stft(x_1[0][0], window='hanning', fs=100, nperseg=155)\n",
    "# k2 = istft(Zxx, window='hanning', fs=100, nperseg=155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fac668",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x_train, y_train = build_stfts(x_1, y_1)\n",
    "x_test, y_test = build_stfts(x_2, y_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe100827",
   "metadata": {},
   "source": [
    "# Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 1620)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1620)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1005bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.expand_dims(x_train, axis = 2)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57880d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(y_train)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f443923",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.expand_dims(x_test, axis = 2)\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997736f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array(y_test)\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8761c2ef",
   "metadata": {},
   "source": [
    "# Logs and Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c7de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = f\"{MODEL_NAME} at {strftime('%H:%M')}\"\n",
    "log_dir = os.path.join(\"../log/\", folder_name)\n",
    "\n",
    "try:\n",
    "    os.makedirs(log_dir)\n",
    "except OSError as exception:\n",
    "    print(exception.strerror)\n",
    "else:\n",
    "    print(\"Successfully created dirs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1e592",
   "metadata": {},
   "source": [
    "# Define GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f75dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(3*3*30, use_bias=False, input_shape=(1620,)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Reshape((3, 3, 30)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 9), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(1, 5), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(1, 4), padding='same', use_bias=False, activation='tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ec9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal(dtype=tf.dtypes.float32, shape=[1, 1620], stddev=5)\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "# TensorShape([1, 3, 540, 1])\n",
    "generated_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff74b1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_all(generated_image[0, :, :, 0], \"GAN Generator Noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4470704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=adam,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69362c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, Y, epochs=25, validation_data=(T, Q), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509817ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(T, Q, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a19e111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc60f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11fb87684b5e7e8b7a77280a5a30a28e41ff00f13a000705cb6714e5054607b4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
